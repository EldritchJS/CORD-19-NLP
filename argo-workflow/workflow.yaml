apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  namespace: <PROJECT_NAME>
  generateName: cord-19
  labels:
    app: process-cord-19
spec:
  serviceAccountName: argo-workflow
  entrypoint: entrypoint
  volumeClaimTemplates:
    - metadata:
        name: data-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 10Gi

  templates:
    - name: entrypoint
      steps:
        - - name: cord-19-acquisition
            template: data-acquisition
            arguments: 
              parameters:
              - name: source
                value: "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-08-13/metadata.csv"
        - - name: cord-19-processing
            template: data-processing
    - name: data-acquisition
      inputs:
        parameters:
        - name: source
      container:
        name: data-acquisition
        image: image-registry.openshift-image-registry.svc:5000/jschless-test/cord-19-nlp-acq
        env: 
          - name: SOURCE_URL
            value: "{{inputs.parameters.source}}"
        command: []
        volumeMounts:
          - name: data-storage
            mountPath: /mnt/data
    - name: data-processing
      container: 
        name: data-processing
        image: image-registry.openshift-image-registry.svc:5000/jschless-test/cord-19-nlp-proc
        env:
          - name: KAFKA_BROKERS
            value: "kafka:9092"
          - name: KAFKA_TOPIC
            value: "cord-19-nlp"
        command: []
        volumeMounts:
          - name: data-storage
            mountPath: /mnt/data

